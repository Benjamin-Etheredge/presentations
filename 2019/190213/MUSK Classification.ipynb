{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification with Scikit-Learn\n",
    "\n",
    "This notebook is a walkthrough of different classification approaches provided by the Scikit-Learn library.\n",
    "\n",
    "The dataset that we will use for this example was provided by the UCI Machine Learning Repository and can be found here: <a href=\"https://archive.ics.uci.edu/ml/datasets/Musk+(Version+2)\">Musk (Version 2) Data Set</a>\n",
    "\n",
    "## From the description:\n",
    "\n",
    "### Data Set Information:\n",
    "\n",
    "This dataset describes a set of 102 molecules of which 39 are judged by human experts to be musks and the remaining 63 molecules are judged to be non-musks. The goal is to learn to predict whether new molecules will be musks or non-musks. However, the 166 features that describe these molecules depend upon the exact shape, or conformation, of the molecule. Because bonds can rotate, a single molecule can adopt many different shapes. To generate this data set, all the low-energy conformations of the molecules were generated to produce 6,598 conformations. Then, a feature vector was extracted that describes each conformation. \n",
    "\n",
    "This many-to-one relationship between feature vectors and molecules is called the \"multiple instance problem\". When learning a classifier for this data, the classifier should classify a molecule as \"musk\" if ANY of its conformations is classified as a musk. A molecule should be classified as \"non-musk\" if NONE of its conformations is classified as a musk.\n",
    "\n",
    "\n",
    "## Loading data\n",
    "\n",
    "First we will load this data from the csv file into a Pandas dataframe and get a look at it.\n",
    "\n",
    "You can see that by using a 0 based index, the features are in columns 3-168 and the class is in column 169.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "\n",
    "df = pd.read_csv(\"data/musk_csv.csv\") \n",
    "# Preview the first 5 lines of the loaded data \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Total number of rows: %d\" % len(df))\n",
    "print(\"Breakdown by class:\")\n",
    "print(df.groupby('class').size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training & Validation\n",
    "\n",
    "Before we start looking at different methods for classification, we need to split this data into a training set and a validation set. The problem is that if we train using all of the data, we do not have an independent way of testing the accuracy of the model.\n",
    "\n",
    "Luckily, scikit-learn provides an easy way to do this: [train_test_split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)\n",
    "\n",
    "First, we will slice the original dataframe to create a dataframe with only the 166 attributes, and another with only the classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df.iloc[:,3:169]\n",
    "y = df.iloc[:, 169]\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size=.25)\n",
    "\n",
    "chance = 0.5 ** 10 * 100\n",
    "print(\"Chance of hittings heads ten times in a row: \" + str(chance))\n",
    "print(y.mean())\n",
    "print(ytrain.mean())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier Testing Approach\n",
    "\n",
    "Now that we have the data ready for training and validation, we can start working through the different classifiers provided by scikit-learn. To do that, we will look at two primary measurements of each classifier:\n",
    "1. Accuracy - what percentage of the overal set did the model classify correctly\n",
    "2. Confusion Matrix - which classes were classified correctly, and which were classified as the opposite\n",
    "\n",
    "Here is a great write-up for a [Confusion Matrix](https://www.dataschool.io/simple-guide-to-confusion-matrix-terminology/)\n",
    "\n",
    "A good place to start for finding a list of classifiers is [here](https://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine\n",
    "\n",
    "The first classifier that we will look at is the [Support Vector Classifier](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html)\n",
    "\n",
    "This can be used with several different kernel types. We will start with the default 'rbf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC  # \"Support Vector Classifier\"\n",
    "clf = SVC(kernel='rbf', gamma='scale')\n",
    "clf.fit(Xtrain, ytrain)\n",
    "ypred = clf.predict(Xtest)\n",
    "print(\"Accuracy: %f\\n\" % metrics.accuracy_score(ypred, ytest))\n",
    "\n",
    "confusion_matrix = metrics.confusion_matrix(ypred, ytest)\n",
    "print(\"Confusion Matrix: \")\n",
    "print(confusion_matrix)\n",
    "print()\n",
    "\n",
    "plt.imshow(confusion_matrix,\n",
    "           interpolation='nearest', cmap=plt.cm.binary)\n",
    "plt.grid(False)\n",
    "plt.colorbar()\n",
    "plt.xlabel(\"predicted label\")\n",
    "plt.ylabel(\"true label\");\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine\n",
    "\n",
    "Next we will try the linear classifier. Note - this takes a long time..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2h 15min 33s, sys: 97.1 ms, total: 2h 15min 34s\n",
      "Wall time: 2h 15min 33s\n",
      "Accuracy: 0.949697\n",
      "\n",
      "Confusion Matrix: \n",
      "[[1366   54]\n",
      " [  29  201]]\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVcAAAEKCAYAAACmIRYxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAIABJREFUeJzt3X+4HVV97/H3hwBBlB+BAKZAJGhU8BfguQGLV0F+GKg3oVe4hqsl0HDzYEFUakuoPqSG2obWe6lYRCKkBKUBRC2nGsQYoFQwIYkiEH6YY/gVEwkhEFEUCH7vH7MODJu9z5m9z8zZ++x8Xs+znz2z1pqZNSd5vmedNbPWUkRgZmbl2qbdFTAz60YOrmZmFXBwNTOrgIOrmVkFHFzNzCrg4GpmVoG2BFdJu0laLGl1+h7ToNyLku5Kn95c+gRJy9Lx10rafvhqb2Y2uHa1XGcBSyJiIrAk7dfzu4g4KH2m5NIvBC5Kxz8FzKi2umZmzVE7BhFIehA4IiLWSxoH3BoRb6lT7jcR8bqaNAFPAK+PiC2S3gP8bUR8cFgqb2ZWwLZtuu5eEbEeIAXYPRuU20HSCmALMDci/h3YHXg6IrakMmuBvRtdSNJMYGbafXcptbdhc8ghh7S7CtaERx55hI0bN2oo55DUTIvvpoiYPJTrVaWy4Crph8Dr62R9tonTjI+IdZL2B26WdA/w6zrlGv5jRMQ8YF6qk8f6jjDLli1rdxWsCYceeuhwX3LscF+wqMqCa0Qc3ShP0uOSxuW6BTY0OMe69L1G0q3AwcC3gF0lbZtar/sA60q/ATNrm6z3b3CdPDdKux5o9QLT0/Z04IbaApLGSBqdtscChwP3RfbTvAU4caDjzWzk2mabbQp9Olm7ajcXOEbSauCYtI+kHkmXpzIHACsk/YwsmM6NiPtS3rnAOZL6yPpgrxjW2ptZpSQV+nSytjzQiogngaPqpK8ATk/bdwDvaHD8GmBSlXU0s/YYCYGziHa9LWBm1pCDq5lZBRxczcwq4OBqZlYySR3/JkARDq5m1nHccjUzq4CDq5lZBRxczcwq4OBqZlYyP9AyM6uIW65mZhVwcDUzq4CDq5lZyTxxi5lZRRxczcwq4LcFzMwq4JarmVnJ3OdqZlaRbgiubenYkLSbpMWSVqfvMXXKHCTpx5JWSbpb0kdyeVdKekjSXelz0PDegZlVqaw1tCTNl7RB0r25tH+S9ECKK9+RtGsu7zxJfZIelPTBXPrklNYnaVaRe2hXr/EsYElETASWpP1azwKnRMTbgMnAP+d/CMBfRcRB6XNX9VU2s+FS4uqvV5LFj7zFwNsj4p3Az4HzACQdCEwD+mPOVySNkjQKuAQ4DjgQODmVHfgeit1q6aYCC9L2AuCE2gIR8fOIWJ221wEbgD2GrYZm1hZFW61FWq4RcRuwqSbtBxGxJe0uBfZJ21OBayLiuYh4COgjWwh1EtAXEWsi4nngmlR2QO0KrntFxHqA9L3nQIUlTQK2B36RS/5CatZfJGl0dVU1s+HWRHAdK2lF7jOzyUv9OXBj2t4beCyXtzalNUofUGUPtCT9EHh9nazPNnmeccDXgekR8YeUfB7wK7KAOw84F5jT4PiZQLM/cDNroyYeaG2MiJ4Wr/FZYAtwdX9SnWJB/UZoDHb+yoJrRBzdKE/S45LGRcT6FDw3NCi3M/A94HMRsTR37vVp8zlJ/wp8ZoB6zCMLwEga9AdiZu1X9dsCkqYDHwKOioj+uLAW2DdXbB9gXdpulN5Qu7oFeoHpaXs6cENtAUnbA98BroqIb9bkjUvfIuuvvbf2eDMbucrqc21w7slkf+1OiYhnc1m9wDRJoyVNACYCdwLLgYmSJqS4NC2VHVC73nOdC1wnaQbwKHASgKQe4IyIOB34X8D7gN0lnZqOOzW9GXC1pD3ImvF3AWcMc/3NrCJlTpYtaSFwBFnf7FpgNlm34mhgcQrQSyPijIhYJek64D6y7oIzI+LFdJ6zgJuAUcD8iFg16LVfbhF3P3cLjDwvvPBCu6tgTTj00ENZuXLlkP6m32GHHWL8+PGFyq5evXplq32uVfMILTPrON0wQsvB1cw6joOrmVnJPHGLmVlFHFzNzCrgybLNzCrglquZWcnc52pmVhEHVzOzCji4mplVwA+0zMxK5j5XM7OKOLiamVXAwdXMrAIOrmZmFXBwNTMrWZmTZbeTg6uZdRy3XM3MKuDgamZWgW4Irm3t2JA0WdKDkvokzaqTP1rStSl/maT9cnnnpfQHJX1wOOttZtUpuvJrpwfgtgVXSaOAS4DjgAOBkyUdWFNsBvBURLwJuAi4MB17INnytm8DJgNfSeczsy7g4Do0k4C+iFgTEc8D1wBTa8pMBRak7euBo5T9RKcC10TEcxHxENCXzmdmXWCbbbYp9Olk7azd3sBjuf21Ka1umYjYAmwGdi94LACSZkpaIWlFSfU2s4p1Q8u1nQ+06v1komCZIsdmiRHzgHkAkuqWMbPOMRICZxHtbLmuBfbN7e8DrGtURtK2wC7ApoLHmtkIVVbLVdJ8SRsk3ZtL203SYkmr0/eYlC5JF6cH5XdLOiR3zPRUfrWk6UXuoZ3BdTkwUdIESduTPaDqrSnTC/TfyInAzRERKX1aeptgAjARuHOY6m1mFSuxW+BKsofeebOAJRExEViS9iF7uD4xfWYCl6a67AbMBg4le7Yzuz8gD6RtwTX1oZ4F3ATcD1wXEaskzZE0JRW7AthdUh9wDumHEBGrgOuA+4DvA2dGxIvDfQ9mVo2yHmhFxG1kf+3m5R+ULwBOyKVfFZmlwK6SxgEfBBZHxKaIeApYzKsD9qu0dRBBRCwCFtWknZ/b/j1wUoNjvwB8odIKmtmwa7LPdWzNw+p56TnLQPaKiPUAEbFe0p4pvdGD8sIP0PM8QsvMOk4TwXVjRPSUddk6aU09QM/r7BfFzGyrVPGrWI+nP/dJ3xtSeqMH5S09QHdwNbOOU3FwzT8onw7ckEs/Jb01cBiwOXUf3AQcK2lMepB1bEobkLsFzKzjlPWeq6SFwBFkfbNryZ76zwWukzQDeJSXn+ssAo4nG/H5LHAaQERsknQB2RtOAHMiovYh2as4uJpZR1GJk2VHxMkNso6qUzaAMxucZz4wv5lrO7iaWcfphhFaDq5m1nEcXM3MKuDgamZWsm6ZuMXB1cw6joOrmVkFOn0i7CIcXM2so7hbwMysIg6uZmYVcHA1M6uAg6uZWcnKHP7aTg6uZtZx3HI1M6tANwTXtra9JU2W9GBabXFWnfxzJN2XVmJcIukNubwXJd2VPrULG5rZCFbxfK7Dom0tV0mjgEuAY8hm+l4uqTci7ssV+ynQExHPSvo48I/AR1Le7yLioGGttJkNi04PnEW0s+U6CeiLiDUR8TxwDdnqiy+JiFsi4tm0u5RseQUz62JFW62dHoDbGVybXVFxBnBjbn8HSSskLZV0QqODJM1M5VY0KmNmnaWspbXbqZ0PtAqvqCjpY0AP8P5c8viIWCdpf+BmSfdExC9edcJsmd156TyDrthoZu3X6a3SItoZXAutqCjpaOCzwPsj4rn+9IhYl77XSLoVOBh4VXA1s5GnG4JrO9vVy4GJkiZI2h6YRrb64kskHQxcBkyJiA259DGSRqftscDhQP5BmJmNUN3S59q2lmtEbJF0FtkStaOA+RGxStIcYEVE9AL/BLwO+Gb6QT4aEVOAA4DLJP2B7BfE3Jq3DMxsBOv0wFlEWwcRRMQisuVs82nn57aPbnDcHcA7qq2dmbVLpz+sKqJhcJX0DC8/YOr/NRJpOyJi54rrZmZbqW5ouTb89RARO0XEzumzU25/JwdWM6tK2X2ukj4taZWkeyUtlLRDetazTNJqSdem5z5IGp32+1L+fq3eR6G2t6T3SjotbY+VNKHVC5qZDaas4Cppb+BsspGebyd7vjMNuBC4KCImAk+RvUdP+n4qIt4EXJTKtWTQ4CppNnAucF5K2h74RqsXNDMbTMlvC2wLvEbStsCOwHrgA8D1KX8B0D8QaWraJ+UfpRb7KIq0XP8UmAL8Fl56v3SnVi5mZlZEE8F1bP8IzPSZmT9PRPwS+CLwKFlQ3QysBJ6OiC2pWH506EsjR1P+ZmD3Vu6hyNsCz0dE9I9ukvTaVi5kZlaEmpsse2NE9AxwrjFkrdEJwNPAN4Hj6hStfXhfL68pRe7gOkmXAbtK+j/AD4GvtXIxM7MiSuwWOBp4KCKeiIgXgG8Df0wWz/obl/nRoS+NHE35uwCbWrmHQYNrRHyRrO/hW8CbgfMj4sutXMzMrIgSg+ujwGGSdkx9p0eRjea8BTgxlZkO3JC2e9M+Kf/miGip5Vp0EME9wGvImsf3tHIhM7OiynrPNSKWSboe+AmwhWyO6HnA94BrJP1dSrsiHXIF8HVJfWQt1mmtXnvQ4CrpdOB84Gay/ogvS5oTEfNbvaiZ2UDKHEQQEbOB2TXJa8jmlK4t+3vgpDKuW6Tl+lfAwRHxJICk3YE7AAdXMyvdSJiUpYgiwXUt8Exu/xleOcm1mVmpun1ugXPS5i+BZZJuIOtznQrcOQx1M7OtVLe3XPsHCvyCV05CfUOdsmZmpenq4BoRnx/OipiZwVbU5yppD+CvgbcBO/SnR8QHKqyXmW3FuiG4Fuk1vhp4gGz42OeBh8mWaDEzq0Q3rP5apHa7R8QVwAsR8Z8R8efAYRXXy8y2YiXPitUWRYLrC+l7vaQ/UbZo4D5lXFzSZEkPpolpZ9XJP1XSE5LuSp/Tc3nT00S3qyVNrz3WzEamooG104Nrkfdc/07SLsBfAl8GdgY+PdQLSxoFXAIcQ/Yu7XJJvXUWGrw2Is6qOXY3shEXPWSvh61Mxz411HqZWft1euAsYtDgGhHfTZubgSNLvPYkoC8i1gBIuobsHdoiq7h+EFgcEZvSsYuBycDCEutnZm3S1cFV0pcZYB7DiDh7iNd+aVLaZC1waJ1yH5b0PuDnwKcj4rEGx+5d51jS5LkzAcaPH88jjzwyxGrbcHr44YfbXQVrwgsvvDB4oQK6OrgCKyq+dpFJaf8DWBgRz0k6g2z5hQ8UPDZLjJhHNgsOPT09LU0dZmbDp8nJsjvWQIMIFjTKK8lLk9Im+Qlr++vwZG73a7y8WNha4IiaY28tvYZm1hbd0HJt56+H5cBEZUvcbk82b2JvvoCkcbndKcD9afsm4FhJY9IyDsemNDPrAlvL2wKViIgtks4iC4qjgPkRsUrSHGBFRPQCZ0uaQjbJ7Sbg1HTsJkkX8PJghjn9D7fMbOTr9MBZRNuCK0BELAIW1aSdn9s+j5eX9K49dj6eU9asK3VDcB20W0DSmyUtkXRv2n+npM9VXzUz2xp1yyCCIn2uXyNrPb4AEBF3M4R1ZczMBtMNcwsU6RbYMSLurPktsaWi+piZdXyrtIgiwXWjpDeS3iOVdCKwvtJamdlWbWsJrmeSvYT/Vkm/BB4CPlZprcxsqzUS+lOLKDK3wBrgaEmvBbaJiGcGO8bMbCi2iuAq6fyafQAiYk5FdTKzrVynP6wqosgd/Db3eRE4DtivwjqZ2VauzFexJO0q6XpJD0i6X9J7JO0maXGaD3pxGumJMhenOabvlnRIq/dQpFvg/9ZU9IvUDFM1MytLBX2uXwK+HxEnpqH2OwJ/AyyJiLlpov5ZwLlkjceJ6XMocCn1Z+sbVCtt7x2B/Vu5mJlZEWW1XCXtDLwPuAIgIp6PiKfJ5o7un5xqAXBC2p4KXBWZpcCuNXOcFFakz/UeXp7ObxSwB+D+VjOrTBMt17GS8tOjzkvTjPbbH3gC+FdJ7wJWAp8E9oqI9QARsV7Snql8o7mim379tMirWB/KbW8BHo8IDyIws8o0EVw3RkTPAPnbAocAn4iIZZK+RNYF0PDSddJamgd6wOAqaRvgexHx9lZObmbWrJIny14LrI2IZWn/erLg+rikcanVOg7YkCs/4DzTRQ14BxHxB+Bnksa3cnIzs1aU1ecaEb8CHpP0lpR0FNk6fb1A/6rR04Eb0nYvcEp6a+AwYHN/90GzinQLjANWSbqT7HWs/kpPaeWCZmaDKfltgU8AV6c3BdYAp5E1LK+TNAN4FDgplV0EHA/0Ac+msi0pElw/3+rJzcxaUWZwjYi7gHr9skfVKRtkQ/6HrEhwPT4izs0nSLoQ+M8yKmBmVqsbhr8W6TU+pk7acWVXxMwMumey7IYtV0kfB/4C2F/S3bmsnYDby7i4pMlkoydGAZdHxNya/IuAI9PujsCeEbFrynsRuCflPeo+YLPu0Q1zCwzULfBvwI3AP/DK98KeKWMxQEmjgEvIWsZrgeWSeiPivv4yEfHpXPlPAAfnTvG7iDhoqPUws87T6a3SIhoG14jYDGwGTq7o2pOAvjSlIZKuIRt6dl+D8icDsyuqi5l1kG4Iru1sezcaZvYqkt4ATABuziXvIGmFpKWSTqh3XDp2Ziq34oknniij3mZWoa7vcx0GzQwzmwZcHxEv5tLGR8Q6SfsDN0u6JyJ+8aoTZuOM5wH09PS0NIzNzIZXpwfOItrZcm1mmNk0YGE+ISLWpe81wK28sj/WzEawblj9tZ21Ww5MlDQhjZyYRp15YtOwtTHAj3NpYySNTttjgcNp3FdrZiOIuwWGKCK2SDoLuInsVaz5EbFK0hxgRUT0B9qTgWvSyIl+BwCXSfoD2S+Iufm3DMxsZOv0wFlEO/tciYhFZGN582nn1+z/bZ3j7gDeUWnlzKxtHFzNzCrg4GpmVgEHVzOzkpU8WXbbOLiaWcdxy9XMrAIOrmZmFXBwNTMr2UgYIFCEg6uZdRw/0DIzq4BbrmZmFXBwNTMrmftczcwq0g3BdeT3GptZ1ylzykFJoyT9VNJ30/4EScskrZZ0bZryFEmj035fyt9vKPfg4GpmHafkybI/Cdyf278QuCgiJgJPATNS+gzgqYh4E3BRKtf6PQzlYDOzspU5WbakfYA/AS5P+wI+AFyfiiwA+tfgm5r2SflHaQj9E+5zNbOO00RMGytpRW5/Xlo3r98/A38N7JT2dweejogtaT+/MOpLi6amyfw3p/Ibm78DB1cz60BNBNeNEdHT4BwfAjZExEpJR/Qn1ykaBfKa5uBqZh2npLcFDgemSDoe2AHYmawlu6ukbVPrNb8wav+iqWslbQvsAmxq9eJt7XOVNF/SBkn3NsiXpIvT07u7JR2Sy5uenvatljR9+GptZlUro881Is6LiH0iYj+yBVBvjoiPArcAJ6Zi04Eb0nZv2ifl31yzdl9T2v1A60pg8gD5xwET02cmcCmApN2A2cChwCRgtqQxldbUzIZF/2TZFS6tfS5wjqQ+sj7VK1L6FcDuKf0cYNZQ7qPdCxTeNsi7ZFOBq9Jvj6WSdpU0DjgCWBwRmwAkLSYL0gurrbGZDYeyBxFExK3ArWl7DVmjrLbM74GTyrpmp/e5vvT0Lul/stco/VUkzSRr9TJ+/PhqamlmpfIIreo1enpX+KleRMyLiJ6I6Nljjz1KrZyZVaPMEVrt0unBtf/pXb/+J3uN0s1shCtzEEE7dXpw7QVOSW8NHAZsjoj1wE3AsZLGpAdZx6Y0M+sCFT/QGhZt7XOVtJDs4dRYSWvJ3gDYDiAivgosAo4H+oBngdNS3iZJFwDL06nm9D/cMrORr9NbpUW0+22BkwfJD+DMBnnzgflV1MvM2svB1cysZCOhP7UIB1cz6zgOrmZmFXBwNTOrQKe/CVCEg6uZdRT3uZqZVcTB1cysAg6uZmYVcHA1M6uAg6uZWcn6J8se6RxczazjuOVqZlYBB1czswo4uJqZlcyDCMzMKuIHWmZmFXDL1cysAg6uZmYl65Y+17Z2bEiaL2mDpHsb5H9U0t3pc4ekd+XyHpZ0j6S7JK0YvlqbWdXKWv1V0r6SbpF0v6RVkj6Z0neTtFjS6vQ9JqVL0sWS+lLcOaTVe2h3r/GVwOQB8h8C3h8R7wQuAObV5B8ZEQdFRE9F9TOzNihxae0twF9GxAHAYcCZkg4EZgFLImIisCTtAxwHTEyfmcClrd5DW4NrRNwGNFy1NSLuiIin0u5SYJ9hqZiZtVVZS2tHxPqI+Enafga4H9gbmAosSMUWACek7anAVZFZCuwqaVxL99DKQW0yA7gxtx/ADyStlDSzTXUys5IVbbWmlutYSStyn4axQNJ+wMHAMmCviFgPWQAG9kzF9gYeyx22NqU1bUQ80JJ0JFlwfW8u+fCIWCdpT2CxpAdSS7j22JlkzXvGjx8/LPU1s6Fp4oHWxiLdgpJeB3wL+FRE/HqA89fLiKKVyev4lqukdwKXA1Mj4sn+9IhYl743AN8BJtU7PiLmRURPRPTssccew1FlMxuiEvtckbQdWWC9OiK+nZIf7/9zP31vSOlrgX1zh+8DrGvlHjo6uEoaD3wb+LOI+Hku/bWSdurfBo4F6r5xYGYjT4lvCwi4Arg/Iv5fLqsXmJ62pwM35NJPSW8NHAZs7u8+aFZbuwUkLQSOIOs3WQvMBrYDiIivAucDuwNfST/ILelPgL2A76S0bYF/i4jvD/sNmFklSnzP9XDgz4B7JN2V0v4GmAtcJ2kG8ChwUspbBBwP9AHPAqe1euG2BteIOHmQ/NOB0+ukrwHe9eojzGykU4mTZUfEj6jfjwpwVJ3yAZxZxrVHxAMtM9u6dMMILQdXM+s4Dq5mZhVwcDUzK1m3TNzi4GpmHceTZZuZVcAtVzOzCji4mpmVzH2uZmYVcXA1M6uAg6uZWcnKHP7aTg6uZtZx3HI1M6uAg6uZWQUcXM3MKuDgamZWMr/namZWEb8tYGZWAbdczcwq0A3Bta1tb0nzJW2QVHflVklHSNos6a70OT+XN1nSg5L6JM0avlqbWZWKrvza6QG43S3XK4F/Aa4aoMx/RcSH8gmSRgGXAMeQrTO+XFJvRNxXVUXNbPh0euAsot2rv94mab8WDp0E9KVVYJF0DTAVcHA16wJ+oDU83iPpZ8A64DMRsQrYG3gsV2YtcGi9gyXNBGam3ecadUGMcGOBje2uREW69d669b7eMtQTrFy58iZJYwsW79ifYacH158Ab4iI30g6Hvh3YCL11yGPeieIiHnAPABJKyKip6rKtku33hd07711830N9RwRMbmMurRbR7e9I+LXEfGbtL0I2C79RlsL7Jsrug9Zy9bMrCN0dHCV9Hqlnm1Jk8jq+ySwHJgoaYKk7YFpQG/7ampm9kpt7RaQtBA4AhgraS0wG9gOICK+CpwIfFzSFuB3wLSICGCLpLOAm4BRwPzUFzuYeeXfRUfo1vuC7r0331eXUxarzMysTB3dLWBmNlI5uJqZVaCrg6uk3SQtlrQ6fY9pUO7F3BDbjn0wNtiQX0mjJV2b8pe1OEBj2BW4r1MlPZH7Nzq9HfVsVoHh3ZJ0cbrvuyUdMtx1bMVQhq1vTbo6uAKzgCURMRFYkvbr+V1EHJQ+U4avesXlhvweBxwInCzpwJpiM4CnIuJNwEXAhcNby+YVvC+Aa3P/RpcPayVbdyUw0Dubx5G9tz2RbKDLpcNQpzJcycD3Bdmw9f5/rznDUKeO0+3BdSqwIG0vAE5oY12G6qUhvxHxPNA/5Dcvf7/XA0f1v8rWwYrc14gUEbcBmwYoMhW4KjJLgV0ljRue2rWuwH0Z3R9c94qI9QDpe88G5XaQtELSUkmdGoDrDfndu1GZiNgCbAZ2H5bata7IfQF8OP3pfL2kfevkj0RF730keo+kn0m6UdLb2l2Zduj04a+DkvRD4PV1sj7bxGnGR8Q6SfsDN0u6JyJ+UU4NS1NkyG/hYcEdpEid/wNYGBHPSTqDrHX+gcprVr2R+O9VRKNh61uVER9cI+LoRnmSHpc0LiLWpz+3NjQ4x7r0vUbSrcDBQKcF1yJDfvvLrJW0LbALnf/n26D3FRFP5na/xgjoSy6oK4dxR8Svc9uLJH1F0tiI6NhJVqrQ7d0CvcD0tD0duKG2gKQxkkan7bHA4XTm1IVFhvzm7/dE4Obo/FEig95XTT/kFOD+YaxflXqBU9JbA4cBm/u7sUayAYatb1VGfMt1EHOB6yTNAB4FTgKQ1AOcERGnAwcAl0n6A9l/grmdOOl2RNQd8itpDrAiInqBK4CvS+oja7FOa1+Niyl4X2dLmgJsIbuvU9tW4SYUGN69CDge6AOeBU5rT02bM4Rh61sVD381M6tAt3cLmJm1hYOrmVkFHFzNzCrg4GpmVgEHVzOzCji4WmUk/SZ9/5Gk6wcp+ylJOzZ5/iMkfbdoek2ZUyX9S5PXe1jFVyW1rZyDqzUlzWLVlIhYFxEnDlLsU0BTwdWskzm4GgCS9pP0gKQFuQlSdkx5D0s6X9KPgJMkvVHS9yWtlPRfkt6ayk2Q9GNJyyVdUHPue9P2KElflHRPus4nJJ0N/BFwi6RbUrlj07l+Iumbkl6X0ienev4I+J8F7muSpDsk/TR9vyWXvW+6jwclzc4d8zFJd6a5SC9r5ReKmYOr5b0FmBcR7wR+DfxFLu/3EfHeiLiGbBG6T0TEu4HPAF9JZb4EXBoR/w34VYNrzAQmAAen61wdEReTjak/MiKOTH96fw44OiIOAVYA50jagWxugf8B/HfqT9hT6wHgfRFxMHA+8Pe5vEnAR4GDyH5p9Eg6APgIcHhEHAS8mMqYNaXbh79acx6LiNvT9jeAs4Evpv1rAVIL8o+Bb+amih2dvg8HPpy2v079CVaOBr6apkQkIupNLHMY2cTZt6drbA/8GHgr8FBErE51+QZZsB7ILsACSRPJZpzaLpe3uH9SGEnfBt5LNsT23cDydO3X0GDCH7OBOLhaXu1Y6Pz+b9P3NsDTqVVX5By1VLDM4og4+RWJ0kEFjq11AXBLRPypsmVvbs3l1btfAQsi4rwmr2P2Cu4WsLzxkt6Ttk8GflRbIE0n95Ck/klwJOldKft2Xp4sptGf0j8AzkhTIiJpt5T+DLBT2l4KHC7pTanMjpLeTPYn/gRJb8zVcTC7AL9M26fW5B2jbJ2115CtUnE72XJAJ0ras79+kt5Q4Dpmr+Dgann3A9Ml3Q3sRuM1nT4KzJD0M2AVLy/L8kngTEnLyYJaPZeTzVB2dzr+f6f0ecBNeLnOAAAAf0lEQVSNkm6JiCfIAuHCVJelwFsj4vdk3QDfSw+0HilwT/8I/IOk28lm3cr7EVn3xV3AtyJiRZoR7XPAD9K1FwMdv/SKdR7PimVA9kQf+G5EvL3NVTHrCm65mplVwC1XM7MKuOVqZlYBB1czswo4uJqZVcDB1cysAg6uZmYV+P+1Lf7AKLgnUgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f0f7861d320>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# from sklearn.svm import SVC  # \"Support Vector Classifier\"\n",
    "# clf = SVC(kernel='linear', gamma='scale')\n",
    "# %time clf.fit(Xtrain, ytrain)\n",
    "# ypred = clf.predict(Xtest)\n",
    "# print(\"Accuracy: %f\\n\" % metrics.accuracy_score(ypred, ytest))\n",
    "\n",
    "# confusion_matrix = metrics.confusion_matrix(ypred, ytest)\n",
    "# print(\"Confusion Matrix: \")\n",
    "# print(confusion_matrix)\n",
    "# print()\n",
    "\n",
    "# plt.imshow(confusion_matrix,\n",
    "#            interpolation='nearest', cmap=plt.cm.binary)\n",
    "# plt.grid(False)\n",
    "# plt.colorbar()\n",
    "# plt.xlabel(\"predicted label\")\n",
    "# plt.ylabel(\"true label\");\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Classifier\n",
    "\n",
    "The next classifier that we will look at is the [Decision Tree Classifier](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dtc = DecisionTreeClassifier()\n",
    "dtc.fit(Xtrain, ytrain)\n",
    "ypred = dtc.predict(Xtest)\n",
    "print(\"Accuracy: %f\\n\" % metrics.accuracy_score(ypred, ytest))\n",
    "\n",
    "confusion_matrix = metrics.confusion_matrix(ypred, ytest)\n",
    "print(\"Confusion Matrix: \")\n",
    "print(confusion_matrix)\n",
    "print()\n",
    "\n",
    "plt.imshow(confusion_matrix,\n",
    "           interpolation='nearest', cmap=plt.cm.binary)\n",
    "plt.grid(False)\n",
    "plt.colorbar()\n",
    "plt.xlabel(\"predicted label\")\n",
    "plt.ylabel(\"true label\");\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier\n",
    "\n",
    "The next classifier that we will look at is the [Random Forest Classifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier(n_estimators=100, random_state=0)\n",
    "rfc.fit(Xtrain, ytrain)\n",
    "ypred = rfc.predict(Xtest)\n",
    "print(\"Accuracy: %f\\n\" % metrics.accuracy_score(ypred, ytest))\n",
    "\n",
    "confusion_matrix = metrics.confusion_matrix(ypred, ytest)\n",
    "print(\"Confusion Matrix: \")\n",
    "print(confusion_matrix)\n",
    "print()\n",
    "\n",
    "plt.imshow(confusion_matrix,\n",
    "           interpolation='nearest', cmap=plt.cm.binary)\n",
    "plt.grid(False)\n",
    "plt.colorbar()\n",
    "plt.xlabel(\"predicted label\")\n",
    "plt.ylabel(\"true label\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoost Classifier\n",
    "\n",
    "How about an [AdaBoost Classifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html#sklearn.ensemble.AdaBoostClassifier)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "abc = AdaBoostClassifier(random_state=0)\n",
    "abc.fit(Xtrain, ytrain)\n",
    "ypred = abc.predict(Xtest)\n",
    "print(\"Accuracy: %f\\n\" % metrics.accuracy_score(ypred, ytest))\n",
    "\n",
    "confusion_matrix = metrics.confusion_matrix(ypred, ytest)\n",
    "print(\"Confusion Matrix: \")\n",
    "print(confusion_matrix)\n",
    "print()\n",
    "\n",
    "plt.imshow(confusion_matrix,\n",
    "           interpolation='nearest', cmap=plt.cm.binary)\n",
    "plt.grid(False)\n",
    "plt.colorbar()\n",
    "plt.xlabel(\"predicted label\")\n",
    "plt.ylabel(\"true label\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Naive Bayes\n",
    "\n",
    "Did someone say \"[Gaussian Naive Bays](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html#sklearn.naive_bayes.GaussianNB)\"?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(Xtrain, ytrain)\n",
    "ypred = gnb.predict(Xtest)\n",
    "print(\"Accuracy: %f\\n\" % metrics.accuracy_score(ypred, ytest))\n",
    "\n",
    "confusion_matrix = metrics.confusion_matrix(ypred, ytest)\n",
    "print(\"Confusion Matrix: \")\n",
    "print(confusion_matrix)\n",
    "print()\n",
    "\n",
    "plt.imshow(confusion_matrix,\n",
    "           interpolation='nearest', cmap=plt.cm.binary)\n",
    "plt.grid(False)\n",
    "plt.colorbar()\n",
    "plt.xlabel(\"predicted label\")\n",
    "plt.ylabel(\"true label\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QuadraticDiscriminantAnalysis\n",
    "\n",
    "Everyone's favorite - [QuadraticDiscriminantAnalysis](https://scikit-learn.org/stable/modules/generated/sklearn.discriminant_analysis.QuadraticDiscriminantAnalysis.html#sklearn.discriminant_analysis.QuadraticDiscriminantAnalysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "qda = QuadraticDiscriminantAnalysis()\n",
    "qda.fit(Xtrain, ytrain)\n",
    "ypred = qda.predict(Xtest)\n",
    "print(\"Accuracy: %f\\n\" % metrics.accuracy_score(ypred, ytest))\n",
    "\n",
    "confusion_matrix = metrics.confusion_matrix(ypred, ytest)\n",
    "print(\"Confusion Matrix: \")\n",
    "print(confusion_matrix)\n",
    "print()\n",
    "\n",
    "plt.imshow(confusion_matrix,\n",
    "           interpolation='nearest', cmap=plt.cm.binary)\n",
    "plt.grid(False)\n",
    "plt.colorbar()\n",
    "plt.xlabel(\"predicted label\")\n",
    "plt.ylabel(\"true label\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Nearest Neighbors\n",
    "\n",
    "Will you be my [KNeighborsClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html#sklearn.neighbors.KNeighborsClassifier)?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knc = KNeighborsClassifier()\n",
    "knc.fit(Xtrain, ytrain)\n",
    "ypred = knc.predict(Xtest)\n",
    "print(\"Accuracy: %f\\n\" % metrics.accuracy_score(ypred, ytest))\n",
    "\n",
    "confusion_matrix = metrics.confusion_matrix(ypred, ytest)\n",
    "print(\"Confusion Matrix: \")\n",
    "print(confusion_matrix)\n",
    "print()\n",
    "\n",
    "plt.imshow(confusion_matrix,\n",
    "           interpolation='nearest', cmap=plt.cm.binary)\n",
    "plt.grid(False)\n",
    "plt.colorbar()\n",
    "plt.xlabel(\"predicted label\")\n",
    "plt.ylabel(\"true label\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Layer Perceptron Classifier\n",
    "\n",
    "We can't have AI without [MLPClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html#sklearn.neural_network.MLPClassifier)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp = MLPClassifier()\n",
    "mlp.fit(Xtrain, ytrain)\n",
    "ypred = mlp.predict(Xtest)\n",
    "print(\"Accuracy: %f\\n\" % metrics.accuracy_score(ypred, ytest))\n",
    "\n",
    "confusion_matrix = metrics.confusion_matrix(ypred, ytest)\n",
    "print(\"Confusion Matrix: \")\n",
    "print(confusion_matrix)\n",
    "print()\n",
    "\n",
    "plt.imshow(confusion_matrix,\n",
    "           interpolation='nearest', cmap=plt.cm.binary)\n",
    "plt.grid(False)\n",
    "plt.colorbar()\n",
    "plt.xlabel(\"predicted label\")\n",
    "plt.ylabel(\"true label\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimensionality Reduction\n",
    "\n",
    "Do we really need 166 attributes to be able to classify molecules as MUSK / NON-MUSK?\n",
    "\n",
    "Are any of these attributes dependent on others?\n",
    "\n",
    "We can use [Primary Component Analysis](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html) to give us a bit more information. First let's look at the explained variance ratio of the attributes (components) across the entire dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA().fit(X)\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlabel('number of components')\n",
    "plt.ylabel('cumulative explained variance');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use PCA to reduce the component count while keeping a percentage of the variance. The next step shows that 95% of the variance can be kept with only 35 components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pca = PCA(0.95) # keep 95% of variance\n",
    "Xtotal_xform = pca.fit_transform(X)\n",
    "Xtrain_xform = pca.fit_transform(Xtrain)\n",
    "Xtest_xform = pca.transform(Xtest)\n",
    "print(X.shape)\n",
    "print(Xtotal_xform.shape)\n",
    "print(\"95% of the variance can be represented by \"+ str((Xtrain_xform.shape[1] / X.shape[1] * 100)) + \"% of the original components count!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification with Dimensionality Reduction\n",
    "\n",
    "Now let's try repeating the classification exercise with the reduced dimensionality dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dtc = DecisionTreeClassifier()\n",
    "dtc.fit(Xtrain_xform, ytrain)\n",
    "ypred = dtc.predict(Xtest_xform)\n",
    "print(\"Accuracy: %f\\n\" % metrics.accuracy_score(ypred, ytest))\n",
    "\n",
    "confusion_matrix = metrics.confusion_matrix(ypred, ytest)\n",
    "print(\"Confusion Matrix: \")\n",
    "print(confusion_matrix)\n",
    "print()\n",
    "\n",
    "plt.imshow(confusion_matrix,\n",
    "           interpolation='nearest', cmap=plt.cm.binary)\n",
    "plt.grid(False)\n",
    "plt.colorbar()\n",
    "plt.xlabel(\"predicted label\")\n",
    "plt.ylabel(\"true label\");\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Fold Validation\n",
    "\n",
    "Initially, we have been splitting the data into a 75% training set and a 25% testing set by random sampling. This is commonly called \"Cross-validation\". \n",
    "\n",
    "From [Machine Learning Mastery](https://machinelearningmastery.com/k-fold-cross-validation/):\n",
    "Cross-validation is primarily used in applied machine learning to estimate the skill of a machine learning model on unseen data. That is, to use a limited sample in order to estimate how the model is expected to perform in general when used to make predictions on data not used during the training of the model.\n",
    "\n",
    "An additional approach is known as k-Fold Validation:\n",
    "The procedure has a single parameter called k that refers to the number of groups that a given data sample is to be split into. As such, the procedure is often called k-fold cross-validation. When a specific value for k is chosen, it may be used in place of k in the reference to the model, such as k=10 becoming 10-fold cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 2-fold cross-validation\n",
    "X1, X2, y1, y2 = train_test_split(X, y, test_size=0.5, random_state=0)\n",
    "X1.shape, X2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(SVC(kernel='rbf', gamma='scale').fit(X2, y2).score(X1, y1))\n",
    "print(SVC(kernel='rbf', gamma='scale').fit(X1, y1).score(X2, y2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "cv = cross_val_score(SVC(kernel='rbf', gamma='scale'), X, y, cv=2)\n",
    "cv.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "def plot_learning_curve(estimator):\n",
    "    train_sizes, train_scores, test_scores = learning_curve(estimator, X, y, cv=5)\n",
    "\n",
    "    # train_scores = result[0]\n",
    "    # valid_scores = result[1]\n",
    "    title = \"Learning Curves (\"+ type(estimator).__name__ + \")\"\n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    plt.grid()\n",
    "\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                     color=\"r\")\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "             label=\"Training score\")\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "             label=\"Cross-validation score\")\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.show()\n",
    "\n",
    "plot_learning_curve(GaussianNB())\n",
    "# plot_learning_curve(SVC())\n",
    "plot_learning_curve(DecisionTreeClassifier())\n",
    "plot_learning_curve(RandomForestClassifier(n_estimators=100))\n",
    "plot_learning_curve(AdaBoostClassifier())\n",
    "plot_learning_curve(QuadraticDiscriminantAnalysis())\n",
    "# plot_learning_curve(KNeighborsClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

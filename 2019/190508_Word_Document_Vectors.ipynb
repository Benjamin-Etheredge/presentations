{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Word & Document Vectors\n",
    "\n",
    "Huntsville AI - May 8, 2019\n",
    "\n",
    "Facebook: Huntsville Ai\n",
    "LinkedIn: Huntsville AI\n",
    "GitHub: HSV-AI\n",
    "\n",
    "Mailing List - send an e-mail to jlangley@sessionboard.com to be added"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o0MeNkMb6dk_",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Introduction\n",
    "\n",
    "From [Wikipedia](https://en.wikipedia.org/wiki/Word_embedding): \n",
    "\n",
    "> Word embedding is the collective name for a set of language modeling and feature learning techniques in natural language processing (NLP) where words or phrases from the vocabulary are mapped to vectors of real numbers. Conceptually it involves a mathematical embedding from a space with many dimensions per word to a continuous vector space with a much lower dimension.\n",
    "\n",
    "\n",
    "The main function is to create a vector of numbers that represent a word based on the context in which that word is used. These vectors can then be used in a relative fashion to determine the relatedness of words.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "adWqxBR5zi5I",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Papers\n",
    "\n",
    "Here is a list of the seminal papers that led to the capability available today for word and document vectors:\n",
    "\n",
    "* **2013** - *Distributed Representations of Words and Phrases and their Compositionality*\n",
    "Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg Corrado, Jeffrey Dean -  https://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf\n",
    "\n",
    "* **2013** - *Efficient Estimation of Word Representations in Vector Space* Tomas Mikolov, Kai Chen, Greg Corrado, Jeffrey Dean - https://arxiv.org/pdf/1301.3781.pdf\n",
    "\n",
    "* **2014** - *Distributed Representations of Sentences and Documents*\n",
    "Quoc V. Le, Tomas Mikolov - https://arxiv.org/pdf/1405.4053\n",
    "\n",
    "* **2015** - *From Word Embeddings To Document Distances* Matt J. Kusner, Yu Sun, Nicholas I. Kolkin, Kilian Q. Weinberger - http://proceedings.mlr.press/v37/kusnerb15.pdf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Word Vectors\n",
    "\n",
    "In order to compute the word vectors, we create a neural network and train it to predict things based on either a Skip-gram or Continuous Bag of Words approach. The weights of the hidden layer then become the values used in the word vector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![alt text](https://cdn-images-1.medium.com/max/1000/0*DY41kNV4X5j_PfXA.png)\n",
    "\n",
    "Image from [Efficient Estimation of Word Representations in\n",
    "Vector Space](https://arxiv.org/pdf/1301.3781.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Poos8Og9Bwyd",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![Word2Vec](https://multithreaded.stitchfix.com/assets/posts/2016-05-27-lda2vec/anim00.gif)\n",
    "\n",
    "Image from [StitchFix Blog](https://multithreaded.stitchfix.com/blog/2016/05/27/lda2vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Document Vectors\n",
    "\n",
    "Document Vectors are created by adding an additional document (or paragraph) ID as an input.\n",
    "\n",
    "![alt text](https://cdn-images-1.medium.com/max/800/0*x-gtU4UlO8FAsRvL.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2RUjUhtZ-pH1",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![alt text](https://cdn-images-1.medium.com/max/800/0*NtIsrbd4VQzUKVKr.)\n",
    "\n",
    "\n",
    "Images from [A gentle introduction to Doc2Vec\n",
    "](https://medium.com/scaleabout/a-gentle-introduction-to-doc2vec-db3e8c0cce5e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![Word Vector Image](https://www.tensorflow.org/images/linear-relationships.png)\n",
    "\n",
    "\n",
    "Image from [Vector Representations of Words](https://www.tensorflow.org/tutorials/representation/word2vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1C0elSC-_alg",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![Cosine Similarity](https://cdn-images-1.medium.com/max/800/0*XMW5mf81LSHodnTi.png)\n",
    "\n",
    "\n",
    "Image from [Introduction to Word Embedding and Word2Vec](https://towardsdatascience.com/introduction-to-word-embedding-and-word2vec-652d0c2060fa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Word Movers Distance\n",
    "\n",
    "The distance between words of different sentences can be used to judge the similarity of the sentences or documents.\n",
    "\n",
    "![Word Movers Distance](https://cdn-images-1.medium.com/max/800/1*nTWAm46JMYWXpHVsS9MA5w.png)\n",
    "\n",
    "Image from [From Word Embeddings To Document Distances](https://towardsdatascience.com/word-distance-between-word-embeddings-cc3e9cf1d632)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Z2LFFlyYzcxu",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# References\n",
    "\n",
    "https://github.com/stanfordnlp/GloVe\n",
    "\n",
    "https://github.com/fastai/word-embeddings-workshop\n",
    "\n",
    "https://towardsdatascience.com/lda2vec-word-embeddings-in-topic-models-4ee3fc4b2843\n",
    "\n",
    "https://multithreaded.stitchfix.com/blog/2016/05/27/lda2vec\n",
    "\n",
    "https://stackoverflow.com/questions/38287772/cbow-v-s-skip-gram-why-invert-context-and-target-words\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Application\n",
    "\n",
    "Below, we will walk through some examples from the Fast.ai Word Embeddings Workshop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-05-07 17:50:35--  http://files.fast.ai/models/glove_50_glove_100.tgz\n",
      "Resolving files.fast.ai (files.fast.ai)... 67.205.15.147\n",
      "Connecting to files.fast.ai (files.fast.ai)|67.205.15.147|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 225083583 (215M) [text/plain]\n",
      "Saving to: ‘glove_50_glove_100.tgz’\n",
      "\n",
      "glove_50_glove_100. 100%[===================>] 214.66M   713KB/s    in 5m 31s  \n",
      "\n",
      "2019-05-07 17:56:07 (663 KB/s) - ‘glove_50_glove_100.tgz’ saved [225083583/225083583]\n",
      "\n",
      "glove_vectors_100d.npy\n",
      "glove_vectors_50d.npy\n",
      "words.txt\n",
      "wordsidx.txt\n"
     ]
    }
   ],
   "source": [
    "#Get the data and untar it\n",
    "\n",
    "!wget http://files.fast.ai/models/glove_50_glove_100.tgz \n",
    "\n",
    "!tar xvzf glove_50_glove_100.tgz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "#import packages needed\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "import re\n",
    "import json\n",
    "\n",
    "np.set_printoptions(precision=4, suppress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We will load the glove 50 & 100 vectors as numpy arrays and load the words and word indices as arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "vecs = np.load(\"glove_vectors_100d.npy\")\n",
    "vecs50 = np.load(\"glove_vectors_50d.npy\")\n",
    "\n",
    "with open('words.txt') as f:\n",
    "    content = f.readlines()\n",
    "words = [x.strip() for x in content]\n",
    "\n",
    "wordidx = json.load(open('wordsidx.txt'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Now let's see what this data looks like..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the', ',', '.', 'of', 'to', 'and', 'in', 'a', '\"', \"'s\"]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11853"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordidx['feminist']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'feminist'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words[11853]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "What about that word vector?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.296 ,  0.7626, -0.9866,  0.3776,  0.3194,  0.8286, -0.1686,\n",
       "       -1.4558,  0.1965,  0.3854, -0.3348, -0.6503, -0.2528, -0.11  ,\n",
       "       -0.1545,  0.5354, -0.4527, -0.0516,  0.1312,  0.0744,  0.5001,\n",
       "        0.2151,  0.0688,  0.4347,  0.261 , -0.0371,  0.1385, -1.518 ,\n",
       "        0.0641,  0.149 , -0.0314,  0.5038,  0.2839,  0.3457, -0.4411,\n",
       "       -0.3459, -0.2118,  0.5651, -0.088 , -0.0438, -1.2228,  0.6039,\n",
       "       -0.23  ,  0.2287, -0.2695, -0.9398,  0.2376,  0.3302, -0.2422,\n",
       "        0.6359,  0.1347,  0.5542,  0.1432,  0.2861,  0.0216, -0.7437,\n",
       "        0.3508,  0.362 ,  0.5566,  0.3403,  0.3613,  0.5185, -0.5437,\n",
       "       -0.285 ,  1.1831, -0.1192,  0.2473,  0.0614,  0.4436, -0.244 ,\n",
       "        0.2016,  0.5143, -0.4695, -0.0974, -0.9836, -0.3594,  0.3903,\n",
       "       -0.517 , -0.1659, -1.2132, -1.3228,  0.0578,  0.7022,  0.3492,\n",
       "       -0.9103, -0.381 , -0.1545,  0.4467, -0.009 , -0.9838,  1.0114,\n",
       "       -0.227 ,  0.2697,  0.1566,  0.5613,  0.1175, -0.5755, -0.6324,\n",
       "        0.1052,  1.2465], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vecs[11853]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cosine as dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Smaller numbers mean two words are closer together, larger numbers mean they are further apart.\n",
    "\n",
    "The distance between similar words is low:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.27636247873306274"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist(vecs[wordidx[\"puppy\"]], vecs[wordidx[\"dog\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "And the distance between unrelated words is high:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9621107056736946"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist(vecs[wordidx[\"avalanche\"]], vecs[wordidx[\"antique\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Data Bias\n",
    "\n",
    "The word vectors will pick up any bias that exists in the data used to build the vectors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5098515152931213"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist(vecs[wordidx[\"man\"]], vecs[wordidx[\"genius\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.689783364534378"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist(vecs[wordidx[\"woman\"]], vecs[wordidx[\"genius\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Nearest Neighbors\n",
    "\n",
    "We can also see what words are close to a given word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('antique', 1.1920929e-07),\n",
       " ('antiques', 0.18471009),\n",
       " ('furniture', 0.2613591),\n",
       " ('jewelry', 0.26212162),\n",
       " ('vintage', 0.28011894),\n",
       " ('handmade', 0.32542467),\n",
       " ('furnishings', 0.3287084),\n",
       " ('reproductions', 0.33931458),\n",
       " ('decorative', 0.35905504),\n",
       " ('pottery', 0.3720798)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "\n",
    "neigh = NearestNeighbors(n_neighbors=10, radius=0.5, metric='cosine', algorithm='brute')\n",
    "neigh.fit(vecs)\n",
    "\n",
    "distances, indices = neigh.kneighbors([vecs[wordidx[\"antique\"]]])\n",
    "\n",
    "[(words[int(ind)], dist) for ind, dist in zip(list(indices[0]), list(distances[0]))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Math with Word Vectors\n",
    "\n",
    "You can do some pretty interesting things with these word vectors. We can combine multiple terms and use them as a single input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.0345 -0.1185  0.746   0.3256  0.3256 -1.4699 -0.8715 -0.9421  0.0679\n",
      "  0.922   0.6811 -0.3729  1.0969  0.7196  1.3515  1.2493  0.6621  0.1901\n",
      " -0.2707 -0.0444 -1.232   0.1744  0.7577 -0.9177 -1.2184  0.6959 -0.1966\n",
      " -0.415  -0.3358  0.5452  0.589  -0.0299 -0.9744 -0.8937  0.2283 -0.2092\n",
      " -1.3795  1.7811  0.2269  0.47   -0.3045 -0.1573 -0.478   0.3071  0.4202\n",
      " -0.4434  0.1602  0.1443 -0.9528 -0.5565  0.7537  0.182   1.4008  1.8967\n",
      "  0.595  -3.0072  0.6811 -0.2557  2.0217  0.7825  0.4251  1.3615  0.5902\n",
      " -0.1312  0.9344 -0.5377 -0.3988 -0.6415  0.6527  0.5117  0.7315  0.1396\n",
      "  0.3785 -0.6403 -0.094   0.1076  0.6197  0.2537 -1.4346  1.169   1.6931\n",
      "  0.1458 -0.5981  0.8195 -3.1903  1.2429  2.1481  1.6004  0.2014 -0.2121\n",
      "  0.3698 -0.001  -0.628   0.2869  0.3119 -0.1093 -0.6341 -1.7804  0.5857\n",
      "  0.3702]\n"
     ]
    }
   ],
   "source": [
    "new_vec = vecs[wordidx[\"artificial\"]] + vecs[wordidx[\"intelligence\"]]\n",
    "print(new_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('intelligence', 0.1883161),\n",
       " ('artificial', 0.25617576),\n",
       " ('information', 0.3256532),\n",
       " ('knowledge', 0.336419),\n",
       " ('secret', 0.36480355),\n",
       " ('human', 0.36726683),\n",
       " ('biological', 0.37090683),\n",
       " ('using', 0.3773631),\n",
       " ('scientific', 0.38513905),\n",
       " ('communication', 0.3869152)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distances, indices = neigh.kneighbors([new_vec])\n",
    "\n",
    "[(words[int(ind)], dist) for ind, dist in zip(list(indices[0]), list(distances[0]))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "You can even move from one place to another in the vector space. Beware of bias taking you in unintended directions though. Here's the general sense of the word \"programmer\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('programmer', 0.0),\n",
       " ('programmers', 0.32259798),\n",
       " ('animator', 0.36951017),\n",
       " ('software', 0.38250887),\n",
       " ('computer', 0.40600342),\n",
       " ('technician', 0.41406858),\n",
       " ('engineer', 0.4303757),\n",
       " ('user', 0.4356534),\n",
       " ('translator', 0.43721014),\n",
       " ('linguist', 0.44948018)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distances, indices = neigh.kneighbors([vecs[wordidx[\"programmer\"]]])\n",
    "[(words[int(ind)], dist) for ind, dist in zip(list(indices[0]), list(distances[0]))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Here's the masculine sense of the word \"programmer\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('programmer', 0.17419636),\n",
       " ('programmers', 0.4133587),\n",
       " ('engineer', 0.46376407),\n",
       " ('compiler', 0.46731704),\n",
       " ('software', 0.4681465),\n",
       " ('animator', 0.4892366),\n",
       " ('computer', 0.5046158),\n",
       " ('mechanic', 0.5150067),\n",
       " ('setup', 0.51882535),\n",
       " ('developer', 0.51953185)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_vec = vecs[wordidx[\"programmer\"]] + vecs[wordidx[\"he\"]] - vecs[wordidx[\"she\"]]\n",
    "distances, indices = neigh.kneighbors([new_vec])\n",
    "[(words[int(ind)], dist) for ind, dist in zip(list(indices[0]), list(distances[0]))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Here's the feminine sense of the word \"programmer\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('programmer', 0.19503415),\n",
       " ('stylist', 0.42715955),\n",
       " ('animator', 0.4820645),\n",
       " ('programmers', 0.48337305),\n",
       " ('choreographer', 0.4862678),\n",
       " ('technician', 0.4862805),\n",
       " ('designer', 0.48710012),\n",
       " ('prodigy', 0.49118334),\n",
       " ('lets', 0.49730027),\n",
       " ('screenwriter', 0.49754214)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_vec = vecs[wordidx[\"programmer\"]] - vecs[wordidx[\"he\"]] + vecs[wordidx[\"she\"]]\n",
    "distances, indices = neigh.kneighbors([new_vec])\n",
    "[(words[int(ind)], dist) for ind, dist in zip(list(indices[0]), list(distances[0]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import plotly\n",
    "import plotly.graph_objs as go    \n",
    "from IPython.display import IFrame\n",
    "\n",
    "def plotly_3d(Y, cat_labels):\n",
    "    trace_dict = {}\n",
    "    for i, label in enumerate(cat_labels):\n",
    "        trace_dict[i] = go.Scatter3d(\n",
    "            x=Y[i*5:(i+1)*5, 0],\n",
    "            y=Y[i*5:(i+1)*5, 1],\n",
    "            z=Y[i*5:(i+1)*5, 2],\n",
    "            mode='markers',\n",
    "            marker=dict(\n",
    "                size=8,\n",
    "                line=dict(\n",
    "                    color='rgba('+ str(i*40) + ',' + str(i*40) + ',' + str(i*40) + ', 0.14)',\n",
    "                    width=0.5\n",
    "                ),\n",
    "                opacity=0.8\n",
    "            ),\n",
    "            text = my_words[i*5:(i+1)*5],\n",
    "            name = label\n",
    "        )\n",
    "\n",
    "    data = [item for item in trace_dict.values()]\n",
    "    layout = go.Layout(\n",
    "        margin=dict(\n",
    "            l=0,\n",
    "            r=0,\n",
    "            b=0,\n",
    "            t=0\n",
    "        )\n",
    "    )\n",
    "\n",
    "    plotly.offline.plot({\n",
    "        \"data\": data,\n",
    "        \"layout\": layout\n",
    "    })\n",
    "    \n",
    "def plotly_3d(Y, cat_labels):\n",
    "    trace_dict = {}\n",
    "    for i, label in enumerate(cat_labels):\n",
    "        trace_dict[i] = go.Scatter3d(\n",
    "            x=Y[i*5:(i+1)*5, 0],\n",
    "            y=Y[i*5:(i+1)*5, 1],\n",
    "            z=Y[i*5:(i+1)*5, 2],\n",
    "            mode='markers',\n",
    "            marker=dict(\n",
    "                size=8,\n",
    "                line=dict(\n",
    "                    color='rgba('+ str(i*40) + ',' + str(i*40) + ',' + str(i*40) + ', 0.14)',\n",
    "                    width=0.5\n",
    "                ),\n",
    "                opacity=0.8\n",
    "            ),\n",
    "            text = my_words[i*5:(i+1)*5],\n",
    "            name = label\n",
    "        )\n",
    "\n",
    "    data = [item for item in trace_dict.values()]\n",
    "    layout = go.Layout(\n",
    "        margin=dict(\n",
    "            l=0,\n",
    "            r=0,\n",
    "            b=0,\n",
    "            t=0\n",
    "        )\n",
    "    )\n",
    "\n",
    "    plotly.offline.plot({\n",
    "        \"data\": data,\n",
    "        \"layout\": layout\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Visualization\n",
    "\n",
    "You can use TSNE or PCA dimensionality reduction to visualize the relationship of words/documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10030, 100)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories = [\n",
    "              \"bugs\", \"music\", \n",
    "              \"pleasant\", \"unpleasant\", \n",
    "              \"science\", \"arts\"\n",
    "             ]\n",
    "\n",
    "my_words = [\n",
    "            \"maggot\", \"flea\", \"tarantula\", \"bedbug\", \"mosquito\", \n",
    "            \"violin\", \"cello\", \"flute\", \"harp\", \"mandolin\",\n",
    "            \"joy\", \"love\", \"peace\", \"pleasure\", \"wonderful\",\n",
    "            \"agony\", \"terrible\", \"horrible\", \"nasty\", \"failure\", \n",
    "            \"physics\", \"chemistry\", \"science\", \"technology\", \"engineering\",\n",
    "            \"poetry\", \"art\", \"literature\", \"dance\", \"symphony\",\n",
    "           ]\n",
    "\n",
    "X = np.array([wordidx[word] for word in my_words])\n",
    "\n",
    "embeddings = np.concatenate((vecs[X], vecs[:10000,:]), axis=0); embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import manifold\n",
    "\n",
    "tsne = manifold.TSNE(n_components=3, init='pca', random_state=0)\n",
    "Y = tsne.fit_transform(embeddings)\n",
    "plotly_3d(Y, categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "IFrame('temp-plot.html', width=600, height=400)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "colab": {
   "name": "190508_Word_Document_Vectors.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
